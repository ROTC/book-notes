\chapter{Model Inference and Averaging}
    本章为《The elements of Statistical Learning》第8章的笔记。
    \section{Introduction}
    \section{The Bootstrap and Maximum Likelihood Methods}
        \subsection{A Smoothing Example}
            自助法提供了一种评估不确定性的直接计算方法（置信区间）。
            \begindot
                \item 非参数自助法（与最小二乘法的置信区间类似）
                \item 参数自助法（对每个预测的y值加一个高斯噪声，参数为噪声的方差，此时估计出的函数的置信区间与最小二乘法的完全相同）
            \myenddot
        \subsection{Maximum Likelihood Inference}
            参数自助法与最小二乘法是一致的，因为模型具有加法高斯误差。一般地，参数自助法并非与最小二乘法一致，而是与极大似然一致。
        \subsection{Bootstrap versus Maximum Likelihood}
    \section{Bayesian Methods}
        在用于推理的贝叶斯方法中，$\Pr ({\bf{Z}}|\theta )$是采样模型，先验分布是$\Pr (\theta )$，反映我们看到数据之前的关于$\theta$的知识，后验分布为$\Pr (\theta |{\bf{Z}})$是我们看到数据之后关于$\theta$更新的知识。

        与标准的“频率论”方法的区别是使用先验分布来表达看到数据之前的不确定性，并在看到数据之后允许残余的不确定性以后验分布形式来表示。
    \section{Relationship Between the Bootstrap and Bayesian Inference}
        自助法分布为我们的参数提供了一个（近似的）非参数的、无信息的后验分布。
    \section{The EM Algorithm}
        \subsection{Two-Component Mixture Model}
        \subsection{The EM Algorithm in General}
            公式${\mathop{\rm E}\nolimits} ({\ell _0}(\theta ';{\bf{T}})|{\bf{Z}},{\hat \theta ^{(j)}})$的定义是
            \begin{equation}
                {\mathop{\rm E}\nolimits} ({\ell _0}(\theta ';{\bf{T}})|{\bf{Z}},{\hat \theta ^{(j)}}) = \sum\limits_{{{\bf{Z}}^m}} {{\ell _0}(\theta ';{\bf{T}})} \Pr ({{\bf{Z}}^m}|{\bf{Z}},{\hat \theta ^{(j)}})
            \end{equation}
            根据条件概率的链式法则
            \begin{equation}
              \Pr ({x_2},...,{x_n}|{x_1}) = \prod\nolimits_{i = 2}^n {\Pr ({x_i}|{x_1},...,{x_{i - 1}})}
            \end{equation}
            得$\Pr ({{\bf{Z}}^m},{\bf{Z}}|\theta ') = \Pr({{\bf{Z}}^m}|\theta ')\Pr({\bf{Z}}|{{\bf{Z}}^m},\theta ')$，即
            \begin{equation}
              \Pr ({\bf{Z}}|\theta ') = \frac{{\Pr ({{\bf{Z}}^m},{\bf{Z}}|\theta ')}}{{\Pr ({{\bf{Z}}^m}|{\bf{Z}},\theta ')}}
            \end{equation}
            用对数似然函数表示，$\ell (\theta ';{\bf{Z}}) = {\ell _0}(\theta ';{{\bf{Z}}^m},{\bf{Z}}) - {\ell _1}(\theta ';{{\bf{Z}}^m}|{\bf{Z}})$，其中${\ell _1}$ 基于条件概率密度$\Pr ({{\bf{Z}}^m}|{\bf{Z}},\theta ')$。关于参数$\theta$支配的${\bf{T}}|{\bf{Z}}$取条件期望，得
            \begin{equation}
              \begin{aligned}
                \ell (\theta ';{\bf{Z}}) &= {\mathop{\rm E}\nolimits} [{\ell _0}(\theta ';{\bf{T}})|{\bf{Z}},\theta ] - {\mathop{\rm E}\nolimits} [{\ell _1}(\theta ';{{\bf{Z}}^m}|{\bf{Z}})|{\bf{Z}},\theta ]\\
                 &\equiv Q(\theta ',\theta ) - R(\theta ',\theta )
              \end{aligned}
            \end{equation}
            其中，$R(\theta ',\theta )$的定义是
            \begin{equation}
                R(\theta ',\theta ) = \sum\limits_{{{\bf{Z}}^m}} {{\ell _1}(\theta ';{{\bf{Z}}^m}|{\bf{Z}})} \Pr ({{\bf{Z}}^m}|{\bf{Z}},\theta )
            \end{equation}
            is the expectation of a log-likelihood of a density(indexed by ${\theta '}$), with respect to the same density indexed by $\theta$，当$\theta ' = \theta$时，作为${\theta '}$的函数取最大值。因而，当极大化$Q(\theta ',\theta )$时，可以得出
            \begin{equation}
              \begin{aligned}
                \ell (\theta ';Z) - \ell (\theta ;Z) &= [Q(\theta ',\theta ) - Q(\theta ,\theta )] - [R(\theta ',\theta ) - R(\theta ,\theta )]\\
                &\ge 0
              \end{aligned}
            \end{equation}
        \subsection{EM as a Maximization-Maximization Procedure}
            One does not need to maximize with respect to all of the latent data parameters at once, but could instead maximize over one of them at a time, 而可以在M步轮流一次极大化它们中的一个。
    \section{MCMC for Sampling from the Posterior}
        MCMC(Markov chain Monte Carlo)马尔科夫链蒙特卡洛方法。
    \section{Bagging(装袋)}
        Bagging(Bootstrap aggregation)对自助法样本集上的预测求平均，从而降低方差。真实装袋估计的定义是${{\mathop{\rm E}\nolimits} _{\hat p}}{\hat f^*}(x)$，其中$\hat p$表示经验分布，即从实际总体中而不是数据中抽取样本。
        
        仅当原来的估计是非线性的，或者是数据的自适应函数时，装袋估计与${\hat f}(x)$不同。
    
        对于数模型来说，类概率估计为在末端节点中的类比例，Bagging平均类概率通常可降低方差。
        \subsection{Example: Trees with Simulated Data}
            由于预测子的相关性，这些树具有较高的方差。Bagging成功地光滑了这种方差，从而降低了检验误差。
            
            Bagging可以降低均方误差，因为平均可以降低不稳定过程（如树）的方差，而保持偏倚不变。参考\href{https://www.zhihu.com/question/26760839}{\color{blue} 知乎：为什么说bagging是减少variance，而boosting是减少bias}，由于子集样本集的相似性以及使用的是同种模型，因此各模型有近似相等的bias和variance。由于${\mathop{\rm E}\nolimits} [{{\sum {{x_i}} } \mathord{\left/
 {\vphantom {{\sum {{x_i}} } n}} \right.
 \kern-\nulldelimiterspace} n}] = {\mathop{\rm E}\nolimits} [{x_i}]$，以bagging后的bias和单个子模型的接近，一般来说不能显著降低bias。另一方面，若各子模型独立，${\mathop{\rm var}} ({{\sum {{x_i}} } \mathord{\left/
 {\vphantom {{\sum {{x_i}} } n}} \right.
 \kern-\nulldelimiterspace} n}) = {{{\mathop{\rm var}} ({x_i})} \mathord{\left/
 {\vphantom {{{\mathop{\rm var}} ({x_i})} n}} \right.
 \kern-\nulldelimiterspace} n}$，此时可以显著降低variance。
            
            训练样本是从$P$分布中抽取的不相关的样本(不重复)，而自助样本也是从$P$中采样得到的。
            
            %上面的讨论对于0-1损失不成立，因为偏倚和方差不具有可加性。
            
            当bag一个模型时，模型中任何简单结构都将失去。如bagged树已不再是树，对于模型的解释，这显然是一个缺点。
            
            由bag计算的期望类概率不能在任何一个single replication上实现，在这种其意义上，bag一定程度上增大了各基分类器的模型空间。对于该例子(single split分类器bag拟合双向拟合$x_1+x_2=1$)或者其它例子，模型需要放大时，bag没有帮助。



